{
    "metadata": {
        "language_info": {
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "nbconvert_exporter": "python", 
            "mimetype": "text/x-python", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "version": "2.7.11"
        }, 
        "kernelspec": {
            "name": "python2-spark20", 
            "language": "python", 
            "display_name": "Python 2 with Spark 2.0"
        }
    }, 
    "nbformat": 4, 
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Access dashDB and DB2 with Python\n\nThis notebook shows how to access a dashDB data warehouse or DB2 database when using Python. The examples use a dashDB warehouse, but the instructions apply to both dashDB and DB2.\n\n## Table of contents\n\n1. [Setup](#Setup) \n1. [Import the *ibmdbpy* Python library](#Import-the-ibmdbpy-Python-library)\n1. [Identify and enter the database connection credentials](#Identify-and-enter-the-database-connection-credentials)\n1. [Create the database connection](#Create-the-database-connection)\n1. [Use dataframe to read and manipulate tables](#Use-dataframe-to-read-and-manipulate-tables)\n1. [Close the database connection](#Close-the-database-connection)\n1. [Summary](#Summary)\n\n\n## Setup\n\nBefore beginning you will need a *dashDB* warehouse. dashDB is a fully managed cloud data warehouse, purpose-built for analytics. It offers massively parallel processing (MPP) scale and compatibility with a wide range of business intelligence (BI) tools.  \n\n[Try dashDB free of charge on IBM Bluemix.](https://console.ng.bluemix.net/catalog/services/dashdb)\n\n<a class=\"ibm-tooltip\" href=\"https://console.ng.bluemix.net/catalog/services/dashdb\" target=\"_blank\" title=\"\" id=\"ibm-tooltip-0\">\n<img alt=\"IBM Bluemix.Get started now\" height=\"193\" width=\"153\" src=\"https://ibm.box.com/shared/static/42yt39czuksqdi278xpy96txtlw3lfmb.png\" >\n</a>\n\n\n\n\n\n## Import the *ibmdbpy* Python library\n\nPython support for dashDB and DB2 is provided by the [ibmdbpy Python library](https://pypi.python.org/pypi/ibmdbpy). Connecting to dashDB or DB2 is also enabled by a DB2 driver, libdb2.so.\n\nThe JDBC Connection is based on a Java virtual machine. From the ibmdbpy library you can use JDBC to connect to a remote dashDB/DB2 instance. To be able to use JDBC to connect, we need to import the *JayDeBeApi* package.\n\nRun the following commands to install and load the JayDeBeApi package and the ibmdbpy library into your notebook:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "!pip install jaydebeapi --user  \n!pip install ibmdbpy --user ", 
            "outputs": [], 
            "execution_count": null, 
            "cell_type": "code"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "import jaydebeapi\nfrom ibmdbpy import IdaDataBase\nfrom ibmdbpy import IdaDataFrame", 
            "outputs": [], 
            "execution_count": null, 
            "cell_type": "code"
        }, 
        {
            "metadata": {}, 
            "source": "import os\nos.environ['CLASSPATH'] = \"/usr/local/src/data-connectors-1.4.1/db2jcc4-10.5.0.6.jar\"\n\n! echo $CLASSPATH", 
            "outputs": [], 
            "execution_count": null, 
            "cell_type": "code"
        }, 
        {
            "metadata": {}, 
            "source": "import jpype\nargs='-Djava.class.path=%s' % os.environ['CLASSPATH']\njvm = jpype.getDefaultJVMPath()\njpype.startJVM(jvm, args)", 
            "outputs": [], 
            "execution_count": null, 
            "cell_type": "code"
        }, 
        {
            "source": "\n## Identify and enter the database connection credentials\n\nConnecting to dashDB or a DB2 database requires the following information:\n* Database name \n* Host DNS name or IP address \n* Host port\n* Connection protocol\n* User ID\n* User password\n\nAll of this information must be captured in a connection string in a subsequent step. Provide the dashDB or DB2 connection information as shown:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "dsn_uid = \"\";  # e.g.  dash104434\ndsn_pwd = \"\"   # e.g. xxxx\ndsn_hostname =\"\"  # e.g.  awh-yp-small03.services.dal.bluemix.net\ndsn_port = \"\"   # e.g.  50001\ndsn_database = \"\"   # e.g. BLUDB ", 
            "outputs": [], 
            "execution_count": null, 
            "cell_type": "code"
        }, 
        {
            "source": "## Create the database connection\n\nThe following code snippet creates a connection string `connection_string`\nand uses the `connection_string` to create a DB2 connection object:\n", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "connection_string='jdbc:db2://'+dsn_hostname+':'+dsn_port+'/'+dsn_database+':user='+dsn_uid+';password='+dsn_pwd+\";\" \nidadb=IdaDataBase(dsn=connection_string)", 
            "outputs": [], 
            "execution_count": null, 
            "cell_type": "code"
        }, 
        {
            "source": "## Use dataframe to read and manipulate tables\n\nYou can now use the connection object `conn` to query the database:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "df=idadb.show_tables(show_all = True)\ndf.head(5)", 
            "outputs": [], 
            "execution_count": null, 
            "cell_type": "code"
        }, 
        {
            "metadata": {}, 
            "source": "idadb.exists_table_or_view('GOSALESDW.EMP_EXPENSE_FACT')", 
            "outputs": [], 
            "execution_count": null, 
            "cell_type": "code"
        }, 
        {
            "source": "Using our previously opened IdaDataBase instance named \u2018idadb\u2019, we can open one or several IdaDataFrame objects. They behave like pointers to remote tables.\n\nLet us open the *EMP_EXPENSE_FACT* data set, assuming it is stored in the database under the name \u2018GOSALESDW.EMP_EXPENSE_FACT\u2019. The following cell assigns the dataset to a pandas DataFrame.\n\nThe [Pandas data analysis library](http://pandas.pydata.org/) provides high-performance, easy-to-use data structures and data analysis tools for the Python programming language. Pandas allows easy processing and manipulation of tabular data, so it is a perfect fit for data extracted from relational databases.\n", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "source": "idadf = IdaDataFrame(idadb, 'GOSALESDW.EMP_EXPENSE_FACT')", 
            "outputs": [], 
            "execution_count": null, 
            "cell_type": "code"
        }, 
        {
            "source": "You can very easily explore the data in the IdaDataFrame by using built in functions.\n\nUse IdaDataFrame.head to get the first n records of your data set (default 5):", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "idadf.head(5)", 
            "outputs": [], 
            "execution_count": null, 
            "cell_type": "code"
        }, 
        {
            "source": "Use IdaDataFrame.tail to get the last n records of your data set (default 5):", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "idadf.tail(5)", 
            "outputs": [], 
            "execution_count": null, 
            "cell_type": "code"
        }, 
        {
            "source": "__Note:__ Because dashDB operates on a distributed system, the order of rows using IdaDataFrame.head and IdaDataFrame.tail is not guaranteed unless the table is sorted (using an \u2018ORDER BY\u2019 clause) or a column is declared as index for the IdaDataFrame (parameter/attribute indexer).\n\nIdaDataFrame also implements most attributes that are available in a pandas DataFrame:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "idadf.shape", 
            "outputs": [], 
            "execution_count": null, 
            "cell_type": "code"
        }, 
        {
            "metadata": {}, 
            "source": "idadf.columns", 
            "outputs": [], 
            "execution_count": null, 
            "cell_type": "code"
        }, 
        {
            "source": "Several standard statistics functions from the pandas interface are also available for IdaDataFrame. For example, let us calculate the covariance matrix for the iris data set:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "idadf.cov()", 
            "outputs": [], 
            "execution_count": null, 
            "cell_type": "code"
        }, 
        {
            "source": "It is possible to subset the rows of an IdaDataFrame by accessing the IdaDataFrame with a slice object. You can also use the IdaDataFrame.loc attribute, which contains an ibmdbpy.Loc object. However, the row selection might be inaccurate if the current IdaDataFrame is not sorted or does not contain an indexer. This is due to the fact that dashDB stores the data across several nodes if available. Moreover, because dashDB is a column oriented database, row numbers are undefined:", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "idadf_new = idadf[0:9] # Select the first 10 rows\nidadf_new.head()", 
            "outputs": [], 
            "execution_count": null, 
            "cell_type": "code"
        }, 
        {
            "source": "## Close the database connection\n\nTo ensure expected behaviors, IdaDataBase instances need to be closed. Closing the *IdaDataBase* is equivalent to closing the connection: once the connection is closed, it is no longer possible to use the *IdaDataBase* instance and any IdaDataFrame instances that were opened on this connection.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "metadata": {}, 
            "source": "idadb.close()", 
            "outputs": [], 
            "execution_count": null, 
            "cell_type": "code"
        }, 
        {
            "source": "## Summary\n\nThis notebook demonstrated how to establish a connection to a dashDB / DB2 database from Python using the ibmdbpy library.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "## Want to learn more?\n### Free courses on <a href=\"https://bigdatauniversity.com/courses/?utm_source=tutorial-dashdb-python&utm_medium=github&utm_campaign=bdu/\" rel=\"noopener noreferrer\" target=\"_blank\">Big Data University</a>: <a href=\"https://bigdatauniversity.com/courses/?utm_source=tutorial-dashdb-python&utm_medium=github&utm_campaign=bdu\" rel=\"noopener noreferrer\" target=\"_blank\"><img src = \"https://ibm.box.com/shared/static/xomeu7dacwufkoawbg3owc8wzuezltn6.png\" width=600px> </a>", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "### Authors\n\n**Saeed Aghabozorgi**, PhD, is a Data Scientist in IBM with a track record of developing enterprise-level applications that substantially increases clients' ability to turn data into actionable knowledge. He is a researcher in the data mining field and an expert in developing advanced analytic methods like machine learning and statistical modelling on large data sets.\n\n**Polong Lin** is a Data Scientist at IBM in Canada. Under the Emerging Technologies division, Polong is responsible for educating the next generation of data scientists through Big Data University. Polong is a regular speaker in conferences and meetups, and holds an M.Sc. in Cognitive Psychology.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }, 
        {
            "source": "Copyright \u00a9 2016, 2017 Big Data University. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\" rel=\"noopener noreferrer\" target=\"_blank\">MIT License</a>.", 
            "metadata": {}, 
            "cell_type": "markdown"
        }
    ]
}